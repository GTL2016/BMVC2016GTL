\subsection{Classification}

One of the major challenges of classification is to properly define classes. We chose to discretize the position into 2,5-meters segments with no overlap. This was done by imagining a circle centered on the lake, and dividing the lake perimeter in angular sectors. Since the heading is not constant during navigation and can vary a lot without positional change, we also included the orientation of the camera with 10 degrees increments. The objective is to ensure that the images are consistent within each class to limit unnecessary noise during training. 

This representation of robot poses is very sparse, so to improve the efficency of the training, we will limit the number of classes studied. We also need to avoid having a class too strong against the other during the training, our choice is to keep only the classes that have a number of images of at least 50\% of the highest class image count. For our database, the highest class count reaching 1750 images, this translated in around 1000 images for most classes, with 295 classes giving us 300 000 images in total for the training set. The validation set was composed of 10 000 images and the training set of 5000. These sets were created by parsing all surveys and randomly selecting a set to enter each image.

We train an implementation of AlexNet on Caffe. We chose Caffe over other deep learning framework because it was easy to use especially for a classification task. AlexNet is a recognized network used for classification. We did not change the network structure, but in training it from scratch, we tuned the number of images used, the size of the mini-batches and the learning rate. We had to find a trade-off between learning time and precision. We used smaller datasets on first attempts in order to test the training and to tune those parameters.

The aim was not to obtain a great classification, but to create good features for each class. This means that we are aiming at obtaining convolutional layers that are well formed and rich enough to give a good representation of the image while staying independent of seasonal and local changes.

As such, we averaged filter responses for every layer over all images in a class. We could thus minimize the impact of variance over the class images (slight heading and position variations). The average of the filters responses for one layer of one image gives us a good representation of this image. It can be compared to the prototype of any classes giving us a metric for the similarity of an image to a given class. 
